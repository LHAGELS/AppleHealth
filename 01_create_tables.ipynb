{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the XML file exported form Apple Health app\n",
    "XML_DATA = \"C:/Users/LHAGELS/Downloads/Export/apple_health_export/Export.xml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse XML file exported from Apple Health app\n",
    "tree = ET.parse(XML_DATA)\n",
    "root = tree.getroot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Record', 'ActivitySummary', 'ExportDate', 'Workout', 'Me']\n"
     ]
    }
   ],
   "source": [
    "attributes = []\n",
    "for child in root:\n",
    "    attributes.append(child.tag)\n",
    "\n",
    "attributes = list(set(attributes))\n",
    "print(attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Record', 'ActivitySummary', 'Workout']\n"
     ]
    }
   ],
   "source": [
    "attributes.remove('ExportDate')\n",
    "attributes.remove('Me')\n",
    "\n",
    "print(attributes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "records_list = [x.attrib for x in root.iter('Record')]\n",
    "df_records = pd.DataFrame(records_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = '2023-01-01'\n",
    "\n",
    "df_records_2023 = df_records[pd.to_datetime(df_records['startDate']).dt.strftime('%Y-%m-%d') >= start_date]\n",
    "df_records = df_records_2023\n",
    "\n",
    "# remove 'sourceName', 'sourceVersion', 'device', 'creationDate', 'endDate' columns\n",
    "df_records = df_records.drop(['sourceName','sourceVersion', 'device'], axis=1)\n",
    "\n",
    "# parse date columns\n",
    "df_records['Date'] = pd.to_datetime(df_records['startDate']).dt.strftime('%Y-%m-%d')\n",
    "df_records['Time'] = pd.to_datetime(df_records['startDate']).dt.strftime('%H:%M:%S')\n",
    "df_records['Day'] = pd.to_datetime(df_records['startDate']).dt.strftime('%A')\n",
    "df_records['Month'] = pd.to_datetime(df_records['startDate']).dt.strftime('%B')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "# value is numeric, NaN if fails\n",
    "df_records['value'] = pd.to_numeric(df_records['value'], errors='coerce')\n",
    "\n",
    "# shorter observation names\n",
    "df_records['type'] = df_records['type'].str.replace('HKQuantityTypeIdentifier', '')\n",
    "df_records['type'] = df_records['type'].str.replace('HKCategoryTypeIdentifier', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BodyMass',\n",
       " 'HeartRate',\n",
       " 'OxygenSaturation',\n",
       " 'RespiratoryRate',\n",
       " 'StepCount',\n",
       " 'DistanceWalkingRunning',\n",
       " 'BasalEnergyBurned',\n",
       " 'ActiveEnergyBurned',\n",
       " 'FlightsClimbed',\n",
       " 'AppleExerciseTime',\n",
       " 'DistanceCycling',\n",
       " 'DistanceSwimming',\n",
       " 'SwimmingStrokeCount',\n",
       " 'RestingHeartRate',\n",
       " 'VO2Max',\n",
       " 'WalkingHeartRateAverage',\n",
       " 'DistanceDownhillSnowSports',\n",
       " 'EnvironmentalAudioExposure',\n",
       " 'HeadphoneAudioExposure',\n",
       " 'WalkingDoubleSupportPercentage',\n",
       " 'SixMinuteWalkTestDistance',\n",
       " 'AppleStandTime',\n",
       " 'WalkingSpeed',\n",
       " 'WalkingStepLength',\n",
       " 'WalkingAsymmetryPercentage',\n",
       " 'StairAscentSpeed',\n",
       " 'StairDescentSpeed',\n",
       " 'AppleWalkingSteadiness',\n",
       " 'RunningStrideLength',\n",
       " 'RunningVerticalOscillation',\n",
       " 'RunningGroundContactTime',\n",
       " 'HeartRateRecoveryOneMinute',\n",
       " 'RunningPower',\n",
       " 'RunningSpeed',\n",
       " 'SleepAnalysis',\n",
       " 'AppleStandHour',\n",
       " 'LowHeartRateEvent',\n",
       " 'HeartRateVariabilitySDNN']"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record_types = list(df_records.type.unique())\n",
    "record_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary of DataFrames for filtered 'record_data'\n",
    "record_dict = {}\n",
    "\n",
    "# create new DataFrame for every interested data\n",
    "for type in record_types:\n",
    "   record_dict[type] = df_records.loc[(df_records['type'].str.contains(type))].rename(columns={\"value\": type}).sort_values(by='Date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Workouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "level_1_list = []\n",
    "level_2_list = []\n",
    "level_3_list = []\n",
    "\n",
    "a_list = list(root.iter('Workout'))\n",
    "for a in range(len(a_list)):\n",
    "    b_list = list(a_list[a])\n",
    "    \n",
    "    for b in range(len(b_list)):\n",
    "        level_1_list.append(b_list[b].tag)\n",
    "        c_list = list(b_list[b])\n",
    "\n",
    "        for c in range(len(c_list)):\n",
    "            level_2_list.append(c_list[c].tag)\n",
    "            d_list = list(c_list[c])\n",
    "\n",
    "            for d in range(len(d_list)):\n",
    "                level_3_list.append(d_list[d].tag)\n",
    "\n",
    "level_1_list = list(set(level_1_list))\n",
    "level_2_list = list(set(level_2_list))\n",
    "level_3_list = list(set(level_3_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MetadataEntry', 'WorkoutRoute', 'WorkoutEvent', 'WorkoutStatistics']\n",
      "['MetadataEntry', 'FileReference']\n",
      "[]\n",
      "['MetadataEntry', 'WorkoutStatistics', 'WorkoutRoute', 'WorkoutEvent', 'FileReference']\n"
     ]
    }
   ],
   "source": [
    "### EMPTY LIST: no further levels to investigate\n",
    "print(level_1_list)\n",
    "print(level_2_list)\n",
    "print(level_3_list)\n",
    "\n",
    "concat_list = list(set(level_1_list + level_2_list + level_3_list))\n",
    "print(concat_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n",
    "workouts = root.findall('.//Workout')\n",
    "total_workouts = len(workouts)\n",
    "\n",
    "for wo in workouts:\n",
    "    index = index + 1\n",
    "    wo.attrib['workout_pk'] = str(index)\n",
    "\n",
    "    for wo_2 in level_1_list:\n",
    "        workouts_2 = wo.findall(f'.//{wo_2}')\n",
    "        for x in workouts_2:\n",
    "            x.attrib['workout_pk'] = str(index)\n",
    "\n",
    "            for wo_3 in level_2_list:\n",
    "                workouts_3 = x.findall(f'.//{wo_3}')\n",
    "                for y in workouts_3:\n",
    "                    y.attrib['workout_pk'] = str(index)\n",
    "\n",
    "tree.write('./output_files/Indexed_XML.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = ET.parse('./output_files/Indexed_XML.xml')\n",
    "root = tree.getroot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "for elem in concat_list:\n",
    "    workouts = root.findall(f'.//{elem}')\n",
    "    globals()[f\"{elem}_list\"] = []\n",
    "    df_list.append(str(f\"{elem}_list\"))\n",
    "    for wo in workouts:\n",
    "        globals()[f\"{elem}_list\"].append(wo.attrib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MetadataEntry_list',\n",
       " 'WorkoutStatistics_list',\n",
       " 'WorkoutRoute_list',\n",
       " 'WorkoutEvent_list',\n",
       " 'FileReference_list']"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_MetadataEntry_list:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>value</th>\n",
       "      <th>workout_pk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HKWasUserEntered</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HKMetadataKeyHeartRateMotionContext</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   key value workout_pk\n",
       "0                     HKWasUserEntered     1        NaN\n",
       "1  HKMetadataKeyHeartRateMotionContext     0        NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_WorkoutStatistics_list:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>startDate</th>\n",
       "      <th>endDate</th>\n",
       "      <th>sum</th>\n",
       "      <th>unit</th>\n",
       "      <th>workout_pk</th>\n",
       "      <th>average</th>\n",
       "      <th>minimum</th>\n",
       "      <th>maximum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HKQuantityTypeIdentifierActiveEnergyBurned</td>\n",
       "      <td>2021-12-02 19:38:33 +0200</td>\n",
       "      <td>2021-12-02 19:58:33 +0200</td>\n",
       "      <td>254</td>\n",
       "      <td>kcal</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HKQuantityTypeIdentifierDistanceCycling</td>\n",
       "      <td>2021-12-02 19:38:33 +0200</td>\n",
       "      <td>2021-12-02 19:58:33 +0200</td>\n",
       "      <td>8.09</td>\n",
       "      <td>km</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         type                  startDate  \\\n",
       "0  HKQuantityTypeIdentifierActiveEnergyBurned  2021-12-02 19:38:33 +0200   \n",
       "1     HKQuantityTypeIdentifierDistanceCycling  2021-12-02 19:38:33 +0200   \n",
       "\n",
       "                     endDate   sum  unit workout_pk average minimum maximum  \n",
       "0  2021-12-02 19:58:33 +0200   254  kcal          1     NaN     NaN     NaN  \n",
       "1  2021-12-02 19:58:33 +0200  8.09    km          1     NaN     NaN     NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_WorkoutRoute_list:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sourceName</th>\n",
       "      <th>sourceVersion</th>\n",
       "      <th>creationDate</th>\n",
       "      <th>startDate</th>\n",
       "      <th>endDate</th>\n",
       "      <th>workout_pk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Apple Watch von Lucas</td>\n",
       "      <td>8.1</td>\n",
       "      <td>2022-03-29 17:39:48 +0200</td>\n",
       "      <td>2022-03-29 16:57:11 +0200</td>\n",
       "      <td>2022-03-29 17:39:47 +0200</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Apple Watch von Lucas</td>\n",
       "      <td>8.1</td>\n",
       "      <td>2022-04-03 11:15:12 +0200</td>\n",
       "      <td>2022-04-03 10:48:45 +0200</td>\n",
       "      <td>2022-04-03 11:15:10 +0200</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              sourceName sourceVersion               creationDate  \\\n",
       "0  Apple Watch von Lucas           8.1  2022-03-29 17:39:48 +0200   \n",
       "1  Apple Watch von Lucas           8.1  2022-04-03 11:15:12 +0200   \n",
       "\n",
       "                   startDate                    endDate workout_pk  \n",
       "0  2022-03-29 16:57:11 +0200  2022-03-29 17:39:47 +0200         72  \n",
       "1  2022-04-03 10:48:45 +0200  2022-04-03 11:15:10 +0200         81  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_WorkoutEvent_list:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>date</th>\n",
       "      <th>duration</th>\n",
       "      <th>durationUnit</th>\n",
       "      <th>workout_pk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HKWorkoutEventTypeSegment</td>\n",
       "      <td>2022-03-29 16:56:57 +0200</td>\n",
       "      <td>13.28115280667941</td>\n",
       "      <td>min</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HKWorkoutEventTypeSegment</td>\n",
       "      <td>2022-03-29 16:56:57 +0200</td>\n",
       "      <td>25.37857104341189</td>\n",
       "      <td>min</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        type                       date           duration  \\\n",
       "0  HKWorkoutEventTypeSegment  2022-03-29 16:56:57 +0200  13.28115280667941   \n",
       "1  HKWorkoutEventTypeSegment  2022-03-29 16:56:57 +0200  25.37857104341189   \n",
       "\n",
       "  durationUnit workout_pk  \n",
       "0          min         72  \n",
       "1          min         72  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_FileReference_list:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>workout_pk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/workout-routes/route_2022-03-29_5.39pm.gpx</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/workout-routes/route_2022-04-03_11.15am.gpx</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           path workout_pk\n",
       "0   /workout-routes/route_2022-03-29_5.39pm.gpx         72\n",
       "1  /workout-routes/route_2022-04-03_11.15am.gpx         81"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for elem in df_list:\n",
    "    object = globals()[elem]\n",
    "    df_name = f\"df_{elem}\"\n",
    "    print(f\"{df_name}:\")\n",
    "    globals()[df_name] = pd.DataFrame(object)\n",
    "    display(pd.DataFrame(object).head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transform dfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### WorkoutStatistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_workoutstatistics_melt = pd.melt(df_WorkoutStatistics_list, \n",
    "                                    id_vars=['workout_pk', 'type','startDate', 'endDate', 'unit'], \n",
    "                                    value_vars=['sum', 'average', 'minimum', 'maximum'], \n",
    "                                    var_name='metric',\n",
    "                                    value_name='value').dropna()\n",
    "\n",
    "# shorter observation names\n",
    "df_workoutstatistics_melt['type'] = df_workoutstatistics_melt['type'].str.replace('HKQuantityTypeIdentifier', '')\n",
    "df_workoutstatistics_melt['type'] = df_workoutstatistics_melt['type'].str.replace('HKCategoryTypeIdentifier', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Workouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "wo_start_end = df_workoutstatistics_melt[['workout_pk', 'startDate', 'endDate']].drop_duplicates()\n",
    "wo_start_end['Date'] = pd.to_datetime(wo_start_end['startDate']).dt.strftime('%Y-%m-%d')\n",
    "wo_start_end['startDate'] = pd.to_datetime(wo_start_end['startDate'])\n",
    "wo_start_end['endDate'] = pd.to_datetime(wo_start_end['endDate'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Investigate Workout Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "record_df = pd.DataFrame()\n",
    "\n",
    "for type in record_types:\n",
    "    frames = [record_df, record_dict[type]]\n",
    "    record_df = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "record_df['Date'] = pd.to_datetime(record_df['startDate']).dt.strftime('%Y-%m-%d')\n",
    "record_df['startDate'] = pd.to_datetime(record_df['startDate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = pd.merge(record_df, wo_start_end, on = 'Date', how='left', suffixes=('_records', '_wo'))\n",
    "merged['isWO'] = np.where((merged['startDate_records'] >= merged['startDate_wo']) & (merged['startDate_records'] <= merged['endDate_wo']), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "wo_records = merged[merged['isWO']==1].drop(['startDate_wo', 'endDate_wo'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "wo_records_types = list(wo_records['type'].unique())\n",
    "wo_records_types.remove('AppleStandTime')\n",
    "wo_records_types.remove('AppleExerciseTime')\n",
    "wo_records_types.remove('AppleStandHour')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "wo_records_melt = pd.melt(wo_records,\n",
    "                     id_vars=[\n",
    "                         'unit', 'creationDate', \n",
    "                         'startDate_records', 'endDate_records', \n",
    "                         'Date', 'Time', 'Day', 'Month', \n",
    "                         'workout_pk', 'isWO'], \n",
    "                     value_vars=wo_records_types, \n",
    "                     var_name='type',\n",
    "                     value_name='value').dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Enrich df_FileReference_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "DimWorkouts = pd.merge(wo_start_end, df_FileReference_list, on = 'workout_pk', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "wo_records_melt.to_parquet('./output_files/frontend_files/FactWoRecords.parquet.gzip', compression='gzip') \n",
    "df_workoutstatistics_melt.to_parquet('./output_files/frontend_files/DimWoStats.parquet.gzip', compression='gzip') \n",
    "DimWorkouts.to_parquet('./output_files/frontend_files/DimWorkouts.parquet.gzip', compression='gzip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Workout Routes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the XML file exported form Apple Health app\n",
    "XML_routes = \"C:/PythonProjects/AppleHealth/input_files/apple_health_export/workout-routes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_route = list(os.listdir(XML_routes))[0]\n",
    "\n",
    "tree = ET.parse(f'{XML_routes}/{example_route}')\n",
    "root = tree.getroot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['{http://www.topografix.com/GPX/1/1}trk', '{http://www.topografix.com/GPX/1/1}metadata']\n"
     ]
    }
   ],
   "source": [
    "attributes = []\n",
    "for child in root:\n",
    "    attributes.append(child.tag)\n",
    "\n",
    "attributes = list(set(attributes))\n",
    "print(attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "level_1_list = []\n",
    "level_2_list = []\n",
    "level_3_list = []\n",
    "level_4_list = []\n",
    "level_5_list = []\n",
    "\n",
    "a_list = list(root.iter('{http://www.topografix.com/GPX/1/1}trk'))\n",
    "for a in range(len(a_list)):\n",
    "    b_list = list(a_list[a])\n",
    "    \n",
    "    for b in range(len(b_list)):\n",
    "        level_1_list.append(b_list[b].tag)\n",
    "        c_list = list(b_list[b])\n",
    "\n",
    "        for c in range(len(c_list)):\n",
    "            level_2_list.append(c_list[c].tag)\n",
    "            d_list = list(c_list[c])\n",
    "\n",
    "            for d in range(len(d_list)):\n",
    "                level_3_list.append(d_list[d].tag)\n",
    "                e_list = list(d_list[d])\n",
    "\n",
    "                for e in range(len(e_list)):\n",
    "                    level_4_list.append(e_list[e].tag)\n",
    "                    f_list = list(e_list[e])\n",
    "\n",
    "                    for f in range(len(f_list)):\n",
    "                        level_5_list.append(f_list[f].tag)\n",
    "\n",
    "level_1_list = list(set(level_1_list))\n",
    "level_2_list = list(set(level_2_list))\n",
    "level_3_list = list(set(level_3_list))\n",
    "level_4_list = list(set(level_4_list))\n",
    "level_5_list = list(set(level_5_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['{http://www.topografix.com/GPX/1/1}name', '{http://www.topografix.com/GPX/1/1}trkseg']\n",
      "['{http://www.topografix.com/GPX/1/1}trkpt']\n",
      "['{http://www.topografix.com/GPX/1/1}ele', '{http://www.topografix.com/GPX/1/1}time', '{http://www.topografix.com/GPX/1/1}extensions']\n",
      "['{http://www.topografix.com/GPX/1/1}course', '{http://www.topografix.com/GPX/1/1}speed', '{http://www.topografix.com/GPX/1/1}hAcc', '{http://www.topografix.com/GPX/1/1}vAcc']\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "### EMPTY LIST: no further levels to investigate\n",
    "print(level_1_list)\n",
    "print(level_2_list)\n",
    "print(level_3_list)\n",
    "print(level_4_list)\n",
    "print(level_5_list)\n",
    "\n",
    "concat_list = list(set(level_1_list + level_2_list + level_3_list + level_4_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "route_metrics = ['trkpt', 'ele', 'time', 'course', 'speed', 'hAcc', 'vAcc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "279 routes added to dataframe!\n"
     ]
    }
   ],
   "source": [
    "combined_routes_df = pd.DataFrame()\n",
    "\n",
    "for file in list(os.listdir(XML_routes)):\n",
    "    route_df = pd.DataFrame()\n",
    "    tree = ET.parse(f'{XML_routes}/{file}')\n",
    "\n",
    "    for metric in route_metrics:\n",
    "        # create metric lists\n",
    "        globals()[f\"list_{metric}\"] = []\n",
    "        source = \"{http://www.topografix.com/GPX/1/1}\"+str(metric)\n",
    "\n",
    "        # loop elements of metric\n",
    "        for elem in tree.findall(f\".//{source}\"):\n",
    "\n",
    "            # add elements to metric lists (trkpt's have different format)\n",
    "            if elem.tag == '{http://www.topografix.com/GPX/1/1}trkpt':\n",
    "                globals()[f\"list_{metric}\"].append(elem.attrib)\n",
    "            else:\n",
    "                globals()[f\"list_{metric}\"].append(elem.text)\n",
    "\n",
    "        # check whether column is time (TIME HAS ALWAYS N+1 ENTRIES --> ignore first entry) \n",
    "        if metric == 'time':\n",
    "            route_df[metric] = globals()[f\"list_{metric}\"][1:]\n",
    "        else:\n",
    "            route_df[metric] = globals()[f\"list_{metric}\"]\n",
    "\n",
    "    # add route name as column\n",
    "    route_df['route_name'] = file\n",
    "    # union \"route\" dataframe to overall \"combined_routes\" dataframe\n",
    "    combined_routes_df = pd.concat([combined_routes_df, route_df])    \n",
    "\n",
    "print(f\"{len(list(combined_routes_df['route_name'].unique()))} routes added to dataframe!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "DimWorkouts['route_name'] = DimWorkouts['path'].str.split(pat = '/')\n",
    "DimWorkouts['route_name'] = DimWorkouts['route_name'].str[-1]\n",
    "DimWoRoutes = pd.merge(combined_routes_df, DimWorkouts[['route_name', 'workout_pk']], on = 'route_name', how = 'left')\n",
    "\n",
    "DimWoRoutes.to_parquet('./output_files/frontend_files/DimWoRoutes.parquet.gzip', compression='gzip')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
